{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class conv_kernel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        H_input: int,\n",
        "        W_input: int,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        kernel_size: tuple,\n",
        "        attention_kernel_size: tuple,\n",
        "        stride=1,\n",
        "        padding=\"same\",\n",
        "        dilation=1,\n",
        "        groups=1,\n",
        "        bias=None,\n",
        "        padding_mode=\"zeros\",\n",
        "        device=None,\n",
        "        dtype=None,\n",
        "        sigma=1.0,\n",
        "        n=2.0,\n",
        "        attention=True,\n",
        "        set_norm_diag_one=False,\n",
        "    ):\n",
        "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
        "\n",
        "        super(conv_kernel, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.attention_kernel_size = attention_kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.groups = groups\n",
        "        self.bias = bias\n",
        "        self.padding_mode = padding_mode\n",
        "        self.attention = attention\n",
        "        self.set_norm_diag_one = set_norm_diag_one\n",
        "\n",
        "        if padding != \"same\" and kernel_size != attention_kernel_size:\n",
        "            raise NotImplementedError(\n",
        "                \"Mismatch in kernel size and attention kernel size. Please use same kernel size for both.\"\n",
        "            )\n",
        "\n",
        "        # Calculate the shape of the output\n",
        "        if padding == \"same\":\n",
        "            self.H_out = H_input\n",
        "            self.W_out = W_input\n",
        "        else:\n",
        "            self.H_out = math.floor(\n",
        "                (H_input + 2 * padding - dilation * (kernel_size[0] - 1) - 1) // stride\n",
        "                + 1\n",
        "            )\n",
        "            self.W_out = math.floor(\n",
        "                (H_input + 2 * padding - dilation * (kernel_size[1] - 1) - 1) // stride\n",
        "                + 1\n",
        "            )\n",
        "\n",
        "        # Define the input kernel weights\n",
        "        self.input_kernel = nn.Parameter(\n",
        "            torch.randn(\n",
        "                (out_channels, in_channels // groups, *kernel_size), **factory_kwargs\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # define the attention kernel weights and the base attention weights\n",
        "        if self.attention:\n",
        "            self.attention_kernel = nn.Parameter(\n",
        "                torch.randn(\n",
        "                    (out_channels, in_channels // groups, *attention_kernel_size),\n",
        "                    **factory_kwargs\n",
        "                ), requires_grad=True\n",
        "            )\n",
        "        self.initilize_kernels()\n",
        "        self.b0 = nn.Parameter(\n",
        "            torch.zeros((out_channels, self.H_out, self.W_out), **factory_kwargs),\n",
        "            requires_grad=True,\n",
        "        )\n",
        "\n",
        "        # Define the normalization weight parameters - im going to CHANGE THIS to try to debug conv shape issue\n",
        "        '''\n",
        "        self.log_Way = nn.Parameter(\n",
        "            0.0 * torch.ones(\n",
        "                (out_channels, self.H_out * self.W_out, self.H_out * self.W_out),\n",
        "                **factory_kwargs\n",
        "            ), requires_grad=False\n",
        "        )\n",
        "        # self.initilize_norm_matrix()\n",
        "\n",
        "        '''\n",
        "        self.log_Way = nn.Parameter(\n",
        "            0.0 * torch.ones(\n",
        "                (out_channels, in_channels, *kernel_size),\n",
        "                #(out_channels, in_channels, self.H_out, self.W_out),\n",
        "                **factory_kwargs\n",
        "            ), requires_grad=False\n",
        "        )\n",
        "        # Define the semi-saturation constant and exponent of activation\n",
        "        self.sigma = nn.Parameter(\n",
        "            torch.tensor(sigma, **factory_kwargs), requires_grad=False\n",
        "        )\n",
        "        self.n = n\n",
        "\n",
        "        # define a small value to prevent division by zero in norm_eqn and sqrt backprop\n",
        "        self.eps = 1e-8\n",
        "\n",
        "        # Define a variable for MSE loss between input gain and attention parameter.\n",
        "        self.input_gain_mse_loss = 0.0\n",
        "\n",
        "    def initilize_kernels(self):\n",
        "        n = self.in_channels\n",
        "        for k in self.kernel_size:\n",
        "            n *= k\n",
        "        stdv = 1.0 / math.sqrt(n)\n",
        "        print(f\"stdv is {stdv}\")\n",
        "        print(f\"input_kernel before .data.uniform is {self.input_kernel}\")\n",
        "        self.input_kernel.data.uniform_(-stdv, stdv)\n",
        "        print(f\"input_kernel after .data.uniform is {self.input_kernel}\")\n",
        "        if self.attention:\n",
        "            n = self.in_channels\n",
        "            for k in self.attention_kernel_size:\n",
        "                n *= k\n",
        "            stdv = 1.0 / math.sqrt(n)\n",
        "            self.attention_kernel.data.uniform_(-stdv, stdv)\n",
        "        return\n",
        "\n",
        "    def initilize_norm_matrix(self):\n",
        "        self.log_Way.data.uniform_(-10.0, 0.0)\n",
        "        self.fill_diagonal(self.log_Way.data, 0.0)\n",
        "        return\n",
        "\n",
        "    @staticmethod\n",
        "    def mat_mul(x, y):\n",
        "        return x @ y.t()\n",
        "\n",
        "    @staticmethod\n",
        "    def fill_diagonal(t, value):\n",
        "        set_diag_one = lambda t: t.fill_diagonal_(value)\n",
        "        _ = torch.func.vmap(set_diag_one)(t)\n",
        "        return\n",
        "\n",
        "    def Way(self):\n",
        "        return self.log_Way.exp()\n",
        "\n",
        "    def B0(self):\n",
        "        return torch.sigmoid(self.b0)\n",
        "\n",
        "    def B1(self, x):\n",
        "        if self.attention:\n",
        "            return torch.sigmoid(\n",
        "                F.conv2d(\n",
        "                    x,\n",
        "                    self.attention_kernel,\n",
        "                    bias=self.bias,\n",
        "                    stride=self.stride,\n",
        "                    padding=self.padding,\n",
        "                    dilation=self.dilation,\n",
        "                    groups=self.groups,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            return self.B0()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        Wzx = self.input_kernel\n",
        "        z = F.conv2d(x, Wzx)\n",
        "\n",
        "        if self.set_norm_diag_one:\n",
        "            with torch.no_grad():\n",
        "                self.fill_diagonal(self.log_Way.data, 0.0)\n",
        "\n",
        "        B0 = self.B0()\n",
        "        B1 = self.B1(x)\n",
        "\n",
        "        # Update the input gain loss\n",
        "        self.input_gain_mse_loss = self.input_gain_mse(B0, B1)\n",
        "\n",
        "        z_conv_in = F.pad(z, (0, 1, 0, 1))\n",
        "\n",
        "        gated_z = B1**self.n * F.relu(z_conv_in) ** self.n\n",
        "        kernel_W = self.Way()\n",
        "\n",
        "        denom = self.sigma ** 2 + F.conv2d(gated_z, kernel_W)\n",
        "        denom = F.pad(self.sigma ** 2 + F.conv2d(gated_z, kernel_W), (0, 1, 0, 1))\n",
        "\n",
        "        norm_response = gated_z/denom\n",
        "\n",
        "        return norm_response\n",
        "\n",
        "    def input_gain_mse(self, B0, B1):\n",
        "        \"\"\"\n",
        "        This function computes the input gain MSE loss. Find the norm of the difference in B1 and B0.\n",
        "        \"\"\"\n",
        "        num_elements = np.prod(B1.shape)\n",
        "        return torch.norm(B1 - B0) / num_elements\n",
        "\n",
        "test_args = {\n",
        "    'H_input': 4,\n",
        "    'W_input': 4,\n",
        "    'in_channels': 1,        # Grayscale input\n",
        "    'out_channels': 1,      # Number of output features\n",
        "    'kernel_size': (2, 2),   # Standard conv kernel size\n",
        "    'attention_kernel_size': (2, 2)\n",
        "}\n",
        "\n",
        "# Example usage:\n",
        "convlayer = conv_kernel(**test_args)\n",
        "\n",
        "data_out = convlayer(torch.randn(1, 1, 4, 4))\n",
        "\n",
        "print(data_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4Qbb2FArIdC",
        "outputId": "217b54ee-e01e-458a-9879-3057b630033f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stdv is 0.5\n",
            "input_kernel before .data.uniform is Parameter containing:\n",
            "tensor([[[[ 0.0876,  0.0539],\n",
            "          [-1.7293,  0.1703]]]], requires_grad=True)\n",
            "input_kernel after .data.uniform is Parameter containing:\n",
            "tensor([[[[-0.0710,  0.4753],\n",
            "          [ 0.4767,  0.0379]]]], requires_grad=True)\n",
            "tensor([[[[0.0000, 0.0310, 0.0498,    nan],\n",
            "          [0.0492, 0.0701, 0.2847,    nan],\n",
            "          [0.1177, 0.3970, 0.0860,    nan],\n",
            "          [   nan,    nan,    nan,    nan]]]], grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YO32UGrE3BAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}